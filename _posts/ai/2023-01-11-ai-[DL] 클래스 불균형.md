---
layout: single
title: "[DL] 클래스 불균형"
categories:
  - ai

toc: ture
toc_sticky: true
---

<!-- 위는 머릿말임 아래부터 포스트 본문 -->

### 1. 클래스 불균형

클래스 불균형(class imbalance)은 머신러닝에서 지도 학습을 위해 사용되는 입력 데이터 중 

특정 클래스가 다른 클래스에 비해 상대적으로 적은 경우를 의미합니다. 

이는 정확도가 낮은 모델을 생성할 수 있고, 정확도가 높은 모델을 생성하기 위해서는 

클래스 불균형을 해결해야 합니다.

### 2. 클래스 불균형을 찾는법

```python
# y의 클래스 값 분류
print(np.unique(y)) # [0 1 2 3 4 5 6 7 8 9]
# 불균형확인
print(np.unique(y,return_counts=True))
```

```python
(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 
array([178, 182, 177, 183, 181, 182, 181, 179, 174, 180], dtype=int64))

```

이런식으로 0이 178개, 1이 182개, 2이 177개 …. 

np.unique 로 클래스 불균형을 찾을 수 있습니다.

### 3. 클래스 불균형 해결방법

클래스 불균형을 해결하는 방법에는 아래와 같은 것들이 있습니다.

1. 오버 샘플링(oversampling)과 언더 샘플링(undersampling)
    1. 오버 샘플링은 적은 클래스의 데이터 수를 증가시키기 위해 중복을 허용하는 방법입니다.
    2. 언더 샘플링은 반대로 많은 클래스의 데이터 수를 줄이기 위해 샘플을 제거하는 방법입니다.
2. 가중치 조정(weight adjustment)
3. 이외 다양한 샘플링 기법

[[ML] Class imbalance 해결을 위한 다양한 Sampling 기법](https://techblog-history-younghunjo1.tistory.com/123)

### 4.  stratify = y

```python
x_train, x_test, y_train,y_test = train_test_split(x,y,
                                                   train_size=0.8,
                                                   shuffle = True,
                                                   #  stratify 는 데이터 불균형을 해결해줌
                                                   stratify=y
                                                   random_state=21
                                                   )
```

`stratify`매개변수는 훈련데이터 와 학습 데이터의 클래스 비율을 비슷하게 만들어줘 클래스 불균형을 줄여줍니다.